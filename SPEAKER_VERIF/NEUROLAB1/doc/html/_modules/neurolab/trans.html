
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>neurolab.trans &mdash; NeuroLab 0.2.2 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.2.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="NeuroLab 0.2.2 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">NeuroLab 0.2.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for neurolab.trans</h1><pre>
ï»¿# -*- coding: utf-8 -*-
"""
Transfer function with derivatives

:Example:
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; f = TanSig()
    &gt;&gt;&gt; x = np.linspace(-5,5,100)
    &gt;&gt;&gt; y = f(x)
    &gt;&gt;&gt; df_on_dy = f.deriv(x, y) # calc derivative
    &gt;&gt;&gt; f.out_minmax    # list output range [min, max]
    [-1, 1]
    &gt;&gt;&gt; f.inp_active    # list input active range [min, max]
    [-2, 2]
"""

import numpy as np


<div class="viewcode-block" id="TanSig"><a class="viewcode-back" href="../../lib.html#neurolab.trans.TanSig">[docs]</a>class TanSig:
    """
    Hyperbolic tangent sigmoid transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            The corresponding hyperbolic tangent values.
    :Example:
        &gt;&gt;&gt; f = TanSig()
        &gt;&gt;&gt; f([-np.Inf, 0.0, np.Inf])
        array([-1.,  0.,  1.])
    """
    # output range
    out_minmax = [-1, 1]
    # input active range
    inp_active = [-2, 2]

    def __call__(self, x):
        return np.tanh(x)

<div class="viewcode-block" id="TanSig.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.TanSig.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function TanSig

        """
        return 1.0 - np.square(y)

</div></div>
<div class="viewcode-block" id="PureLin"><a class="viewcode-back" href="../../lib.html#neurolab.trans.PureLin">[docs]</a>class PureLin:
    """
    Linear transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            copy of x
    :Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; f = PureLin()
        &gt;&gt;&gt; x = np.array([-100., 50., 10., 40.])
        &gt;&gt;&gt; f(x).tolist()
        [-100.0, 50.0, 10.0, 40.0]

    """

    out_minmax = [-np.Inf, np.Inf]
    inp_active = [-np.Inf, np.Inf]

    def __call__(self, x):
        return x.copy()

<div class="viewcode-block" id="PureLin.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.PureLin.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function PureLin

        """
        return np.ones_like(x)

</div></div>
<div class="viewcode-block" id="LogSig"><a class="viewcode-back" href="../../lib.html#neurolab.trans.LogSig">[docs]</a>class LogSig:
    """
    Logarithmic sigmoid transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            The corresponding  logarithmic sigmoid values.
    :Example:
        &gt;&gt;&gt; f = LogSig()
        &gt;&gt;&gt; x = np.array([-np.Inf, 0.0, np.Inf])
        &gt;&gt;&gt; f(x).tolist()
        [0.0, 0.5, 1.0]


    """

    out_minmax = [0, 1]
    inp_active = [-4, 4]

    def __call__(self, x):
        return 1/(1+np.exp(-x))

<div class="viewcode-block" id="LogSig.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.LogSig.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function LogSig

        """

        return y * (1 - y)

</div></div>
<div class="viewcode-block" id="HardLim"><a class="viewcode-back" href="../../lib.html#neurolab.trans.HardLim">[docs]</a>class HardLim:
    """
    Hard limit transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            may take the following values: 0, 1

    :Example:
        &gt;&gt;&gt; f = HardLim()
        &gt;&gt;&gt; x = np.array([-5, -0.1, 0, 0.1, 100])
        &gt;&gt;&gt; f(x)
        array([ 0.,  0.,  0.,  1.,  1.])

    """

    out_minmax = [0, 1]
    inp_active = [0, 0]

    def __call__(self, x):
        return (x &gt; 0) * 1.0

<div class="viewcode-block" id="HardLim.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.HardLim.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function HardLim

        """
        return np.zeros_like(x)

</div></div>
<div class="viewcode-block" id="HardLims"><a class="viewcode-back" href="../../lib.html#neurolab.trans.HardLims">[docs]</a>class HardLims:
    """
    Symmetric hard limit transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            may take the following values: -1, 1
    :Example:
        &gt;&gt;&gt; f = HardLims()
        &gt;&gt;&gt; x = np.array([-5, -0.1, 0, 0.1, 100])
        &gt;&gt;&gt; f(x)
        array([-1., -1., -1.,  1.,  1.])

    """

    out_minmax = [-1, 1]
    inp_active = [0, 0]

    def __call__(self, x):
        return (x &gt; 0) * 2.0 - 1.0

<div class="viewcode-block" id="HardLims.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.HardLims.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function HardLims

        """
        return np.zeros_like(x)

</div></div>
<div class="viewcode-block" id="Competitive"><a class="viewcode-back" href="../../lib.html#neurolab.trans.Competitive">[docs]</a>class Competitive:
    """
    Competitive transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            may take the following values: 0, 1
            1 if is a minimal element of x, else 0
    :Example:
        &gt;&gt;&gt; f = Competitive()
        &gt;&gt;&gt; f([-5, -0.1, 0, 0.1, 100])
        array([ 1.,  0.,  0.,  0.,  0.])
        &gt;&gt;&gt; f([-5, -0.1, 0, -6, 100])
        array([ 0.,  0.,  0.,  1.,  0.])

    """

    out_minmax = [0, 1]
    inp_active = [-np.Inf, np.Inf]

    def __call__(self, dist):
        r = np.zeros_like(dist)
        min = np.argmin(dist)
        r[min] = 1.0
        return r

</div>
<div class="viewcode-block" id="SoftMax"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SoftMax">[docs]</a>class SoftMax:
    """
    Soft max transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            range values [0, 1]
    :Example:
        &gt;&gt;&gt; from numpy import floor
        &gt;&gt;&gt; f = SoftMax()
        &gt;&gt;&gt; floor(f([0, 1, 0.5, -0.5]) * 10)
        array([ 1.,  4.,  2.,  1.])

    """

    out_minmax = [0, 1]
    inp_active = [-np.Inf, np.Inf]

    def __call__(self, dist):
        exp = np.exp(dist)
        return exp / exp.sum()

</div>
<div class="viewcode-block" id="SatLins"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLins">[docs]</a>class SatLins:
    """
    Symmetric saturating linear transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            -1 if x &lt; -1; x if -1 &lt;= x &lt;= 1; 1 if x &gt;1
    :Example:
        &gt;&gt;&gt; f = SatLins()
        &gt;&gt;&gt; x = np.array([-5, -1, 0, 0.1, 100])
        &gt;&gt;&gt; f(x)
        array([-1. , -1. ,  0. ,  0.1,  1. ])

    """

    out_minmax = [-1, 1]
    inp_active = [-1, 1]

    def __call__(self, x):
        y = x.copy()
        y[y &lt; -1] = -1
        y[y &gt; 1] = 1
        return y

<div class="viewcode-block" id="SatLins.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLins.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function SatLins

        """
        d = np.zeros_like(x)
        d[(x &gt; -1) &amp; (x &lt; 1) ] = 1

        return d

</div></div>
<div class="viewcode-block" id="SatLin"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLin">[docs]</a>class SatLin:
    """
    Saturating linear transfer function

    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            0 if x &lt; 0; x if 0 &lt;= x &lt;= 1; 1 if x &gt;1
    :Example:
        &gt;&gt;&gt; f = SatLin()
        &gt;&gt;&gt; x = np.array([-5, -0.1, 0, 0.1, 100])
        &gt;&gt;&gt; f(x)
        array([ 0. ,  0. ,  0. ,  0.1,  1. ])

    """

    out_minmax = [0, 1]
    inp_active = [0, 1]

    def __call__(self, x):
        y = x.copy()
        y[y &lt; 0] = 0
        y[y &gt; 1] = 1
        return y

<div class="viewcode-block" id="SatLin.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLin.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function SatLin

        """

        d = np.zeros_like(x)
        d[(x &gt; 0) &amp; (x &lt; 1) ] = 1

        return d

</div></div>
<div class="viewcode-block" id="SatLinPrm"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLinPrm">[docs]</a>class SatLinPrm:
    """
    Linear transfer function with parametric output
    May use instead Satlin and Satlins

    :Init Parameters:
        k: float default 1
            output scaling
        out_min: float default 0
            minimum output
        out_max: float default 1
            maximum output
    :Parameters:
        x: ndarray
            Input array
    :Returns:
        y : ndarray
            with default values
            0 if x &lt; 0; x if 0 &lt;= x &lt;= 1; 1 if x &gt;1
    :Example:
        &gt;&gt;&gt; f = SatLinPrm()
        &gt;&gt;&gt; x = np.array([-5, -0.1, 0, 0.1, 100])
        &gt;&gt;&gt; f(x)
        array([ 0. ,  0. ,  0. ,  0.1,  1. ])
        &gt;&gt;&gt; f = SatLinPrm(1, -1, 1)
        &gt;&gt;&gt; f(x)
        array([-1. , -0.1,  0. ,  0.1,  1. ])

    """
    def __init__(self, k=1, out_min=0, out_max=1):
        """
        Linear transfer function with parametric output
        :Init Parameters:
            k: float default 1
                output scaling
            out_min: float default 0
                minimum output
            out_max: float default 1
                maximum output

        """
        self.k = k
        self.out_min = out_min
        self.out_max = out_max
        self.out_minmax = [out_min, out_max]
        self.inp_active = [out_min, out_max]

    def __call__(self, x):
        y = x.copy()
        y[y &lt; self.out_min] = self.out_min
        y[y &gt; self.out_max] = self.out_max
        y[(y &gt;= self.out_min) &amp; (y &lt;= self.out_max)] *= self.k
        return y

<div class="viewcode-block" id="SatLinPrm.deriv"><a class="viewcode-back" href="../../lib.html#neurolab.trans.SatLinPrm.deriv">[docs]</a>    def deriv(self, x, y):
        """
        Derivative of transfer function SatLin

        """
        d = np.zeros_like(x)
        d[(x &gt; self.out_min) &amp; (x &lt; self.out_max) ] = 1

        return d</div></div>
</pre>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">NeuroLab 0.2.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, eje.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>