
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>neurolab.net &mdash; NeuroLab 0.2.2 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.2.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="NeuroLab 0.2.2 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">NeuroLab 0.2.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for neurolab.net</h1><pre>
ï»¿# -*- coding: utf-8 -*-
"""
The module contains the basic network architectures


+-------------------------+------------+---------+-----------------+----------+
|      Network Type       |  Function  | Count of|Support train fcn| Error fcn|
|                         |            | layers  |                 |          |
+=========================+============+=========+=================+==========+
| Single-layer perceptron |    newp    |    1    |   train_delta   |   SSE    |
+-------------------------+------------+---------+-----------------+----------+
| Multi-layer perceptron  |   newff    |  &gt;=1    |   train_gd,     |   SSE    |
|                         |            |         |   train_gdm,    |          |
|                         |            |         |   train_gda,    |          |
|                         |            |         |   train_gdx*,   |          |
|                         |            |         |   train_rprop,  |          |
|                         |            |         |   train_bfgs,   |          |
|                         |            |         |   train_cg      |          |
+-------------------------+------------+---------+-----------------+----------+
|    Competitive layer    |    newc    |    1    |   train_wta,    |   SAE    |
|                         |            |         |   train_cwta*   |          |
+-------------------------+------------+---------+-----------------+----------+
|           LVQ           |   newlvq   |    2    |   train_lvq     |   MSE    |
+-------------------------+------------+---------+-----------------+----------+
|           Elman         |   newelm   |  &gt;=1    |   train_gdx     |   MSE    |
+-------------------------+------------+---------+-----------------+----------+
|         Hopield         |   newhop   |    1    |       None      |   None   |
+-------------------------+------------+---------+-----------------+----------+
|         Hemming         |   newhem   |    2    |       None      |   None   |
+-------------------------+------------+---------+-----------------+----------+

.. note:: \* - default function

"""

from core import Net
import trans
import layer
import train
import error
import init
import numpy as np


<div class="viewcode-block" id="newff"><a class="viewcode-back" href="../../lib.html#neurolab.net.newff">[docs]</a>def newff(minmax, size, transf=None):
    """
    Create multilayer perceptron

    :Parameters:
        minmax: list ci x 2
            Range of input value
        size: list of length equal to the number of layers
            Contains the number of neurons for each layer
        transf: list (default TanSig)
            List of activation function for each layer
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; # create neural net with 2 inputs, 1 output and 2 layers
        &gt;&gt;&gt; net = newff([[-0.5, 0.5], [-0.5, 0.5]], [3, 1])
        &gt;&gt;&gt; net.ci
        2
        &gt;&gt;&gt; net.co
        1
        &gt;&gt;&gt; len(net.layers)
        2

    """

    net_ci = len(minmax)
    net_co = size[-1]

    if transf is None:
        transf = [trans.TanSig()] * len(size)
    assert len(transf) == len(size)

    layers = []
    for i, nn in enumerate(size):
        layer_ci = size[i - 1] if i &gt; 0 else net_ci
        l = layer.Perceptron(layer_ci, nn, transf[i])
        l.initf = init.initnw
        layers.append(l)
    connect = [[i - 1] for i in range(len(layers) + 1)]

    net = Net(minmax, net_co, layers, connect, train.train_gdx, error.SSE())
    return net

</div>
<div class="viewcode-block" id="newp"><a class="viewcode-back" href="../../lib.html#neurolab.net.newp">[docs]</a>def newp(minmax, cn, transf=trans.HardLim()):
    """
    Create one layer perceptron

    :Parameters:
        minmax: list ci x 2
            Range of input value
        cn: int
            Number of neurons
        transf: func (default HardLim)
            Activation function
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; # create network with 2 inputs and 10 neurons
        &gt;&gt;&gt; net = newp([[-1, 1], [-1, 1]], 10)

    """

    ci = len(minmax)
    l = layer.Perceptron(ci, cn, transf)
    net = Net(minmax, cn, [l],  [[-1], [0]], train.train_delta, error.SSE())
    return net

</div>
<div class="viewcode-block" id="newc"><a class="viewcode-back" href="../../lib.html#neurolab.net.newc">[docs]</a>def newc(minmax, cn):
    """
    Create competitive layer (Kohonen network)

    :Parameters:
        minmax: list ci x 2
            Range of input value
        cn: int
            Number of neurons
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; # create network with 2 inputs and 10 neurons
        &gt;&gt;&gt; net = newc([[-1, 1], [-1, 1]], 10)

    """
    ci = len(minmax)
    l = layer.Competitive(ci, cn)
    net = Net(minmax, cn, [l], [[-1], [0]], train.train_cwta, error.SAE())

    return net

</div>
<div class="viewcode-block" id="newlvq"><a class="viewcode-back" href="../../lib.html#neurolab.net.newlvq">[docs]</a>def newlvq(minmax, cn0, pc):
    """
    Create a learning vector quantization (LVQ) network

    :Parameters:
        minmax: list ci x 2
            Range of input value
        cn0: int
            Number of neurons in input layer
        pc: list
            List of percent, sum(pc) == 1
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; # create network with 2 inputs,
        &gt;&gt;&gt; # 2 layers and 10 neurons in each layer
        &gt;&gt;&gt; net = newlvq([[-1, 1], [-1, 1]], 10, [0.6, 0.4])

    """
    pc = np.asfarray(pc)
    assert sum(pc) == 1
    ci = len(minmax)
    cn1 = len(pc)
    assert cn0 &gt; cn1

    layer_inp = layer.Competitive(ci, cn0)
    layer_out = layer.Perceptron(cn0, cn1, trans.PureLin())
    layer_out.initf = None
    layer_out.np['b'].fill(0.0)
    layer_out.np['w'].fill(0.0)
    inx = np.floor(cn0 * pc.cumsum())
    for n, i in enumerate(inx):
        st = 0 if n == 0 else inx[n - 1]
        layer_out.np['w'][n][st:i].fill(1.0)
    net = Net(minmax, cn1, [layer_inp, layer_out],
                            [[-1], [0], [1]], train.train_lvq, error.MSE())

    return net

</div>
<div class="viewcode-block" id="newelm"><a class="viewcode-back" href="../../lib.html#neurolab.net.newelm">[docs]</a>def newelm(minmax, size, transf=None):
    """
    Create a Elman recurrent network

    :Parameters:
        minmax: list ci x 2
            Range of input value
        size: list of length equal to the number of layers
            Contains the number of neurons for each layer
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; net = newelm([[-1, 1]], [1], [trans.PureLin()])
        &gt;&gt;&gt; net.layers[0].np['w'][:] = 1
        &gt;&gt;&gt; net.layers[0].np['b'][:] = 0
        &gt;&gt;&gt; net.sim([[1], [1] ,[1], [3]])
        array([[ 1.],
               [ 2.],
               [ 3.],
               [ 6.]])
    """

    net_ci = len(minmax)
    net_co = size[-1]

    if transf is None:
        transf = [trans.TanSig()] * len(size)
    assert len(transf) == len(size)

    layers = []
    for i, nn in enumerate(size):
        layer_ci = size[i - 1] if i &gt; 0 else net_ci + size[0]
        l = layer.Perceptron(layer_ci, nn, transf[i])
        #l.initf = init.InitRand([-0.1, 0.1], 'wb')
        layers.append(l)
    connect = [[i - 1] for i in range(len(layers) + 1)]
    # recurrent set
    connect[0] = [-1, 0]

    net = Net(minmax, net_co, layers, connect, train.train_gdx, error.MSE())
    return net

</div>
<div class="viewcode-block" id="newhop_old"><a class="viewcode-back" href="../../lib.html#neurolab.net.newhop_old">[docs]</a>def newhop_old(target, transf=None):
    """
    Create a Hopfield recurrent network.

    Old version need tool.simhop for use.
    Will be removed in future versions.

    :Parameters:
        target: array like (l x net.co)
            train target patterns
        transf: func (default HardLims)
            Activation function
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; from neurolab.tool import simhop
        &gt;&gt;&gt; net = newhop_old([[-1, 1, -1], [1, -1, 1]])
        &gt;&gt;&gt; output = simhop(net, [[-1, 1, -1], [1, -1, 1]])
    """

    target = np.asfarray(target)
    ci = len(target[0])
    if transf is None:
        transf = trans.HardLims()
    l = layer.Perceptron(ci, ci, transf)
    w = l.np['w']
    b = l.np['b']

    # init weight
    for i in range(ci):
        for j in range(ci):
            if i == j:
                w[i, j] = 0.0
            else:
                w[i, j] = np.sum(target[:, i] * target[:, j]) / ci
        b[i] = 0.0
    l.initf = None

    minmax = transf.out_minmax if hasattr(transf, 'out_minmax') else [-1, 1]

    net = Net([minmax] * ci, ci, [l], [[0], [0]], None, None)
    return net

</div>
<div class="viewcode-block" id="newhop"><a class="viewcode-back" href="../../lib.html#neurolab.net.newhop">[docs]</a>def newhop(target, transf=None, max_init=10, delta=0):
    """
    Create a Hopfield recurrent network

    :Parameters:
        target: array like (l x net.co)
            train target patterns
        transf: func (default HardLims)
            Activation function
        max_init: int (default 10)
            Maximum of recurent iterations
        delta: float (default 0)
            Minimum diference between 2 outputs for stop reccurent cycle
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; net = newhop([[-1, -1, -1], [1, -1, 1]])
        &gt;&gt;&gt; output = net.sim([[-1, 1, -1], [1, -1, 1]])

    """

    target = np.asfarray(target)
    assert target.ndim == 2

    ci = len(target[0])
    if transf is None:
        transf = trans.HardLims()
    l = layer.Reccurent(ci, ci, transf, max_init, delta)
    w = l.np['w']
    b = l.np['b']

    # init weight
    for i in range(ci):
        for j in range(ci):
            if i == j:
                w[i, j] = 0.0
            else:
                w[i, j] = np.sum(target[:, i] * target[:, j]) / ci
        b[i] = 0.0
    l.initf = None

    minmax = transf.out_minmax if hasattr(transf, 'out_minmax') else [-1, 1]

    net = Net([minmax] * ci, ci, [l], [[-1], [0]], None, None)
    return net

</div>
<div class="viewcode-block" id="newhem"><a class="viewcode-back" href="../../lib.html#neurolab.net.newhem">[docs]</a>def newhem(target, transf=None, max_iter=10, delta=0):
    """
    Create a Hemming recurrent network with 2 layers

    :Parameters:
        target: array like (l x net.co)
            train target patterns
        transf: func (default SatLinPrm(0.1, 0, 10))
            Activation function of input layer
        max_init: int (default 10)
            Maximum of recurent iterations
        delta: float (default 0)
            Minimum diference between 2 outputs for stop reccurent cycle
    :Returns:
        net: Net
    :Example:
        &gt;&gt;&gt; net = newhop([[-1, -1, -1], [1, -1, 1]])
        &gt;&gt;&gt; output = net.sim([[-1, 1, -1], [1, -1, 1]])

    """

    target = np.asfarray(target)
    assert target.ndim == 2

    cn = target.shape[0]
    ci = target.shape[1]

    if transf is None:
        transf = trans.SatLinPrm(0.1, 0, 10)
    layer_inp = layer.Perceptron(ci, cn, transf)

    # init input layer
    layer_inp.initf = None
    layer_inp.np['b'][:] = float(ci) / 2
    for i, tar in enumerate(target):
        layer_inp.np['w'][i][:] = tar / 2

    layer_out = layer.Reccurent(cn, cn, trans.SatLinPrm(1, 0, 1e6), max_iter, delta)
    # init output layer
    layer_out.initf = None
    layer_out.np['b'][:] = 0
    eps = - 1.0 / cn
    for i in range(cn):
        layer_out.np['w'][i][:] = [eps] * cn
        layer_out.np['w'][i][i] = 1
    # create network
    minmax = [[-1, 1]] * ci
    layers = [layer_inp, layer_out]
    connect = [[-1], [0], [1]]
    net = Net(minmax, cn, layers, connect, None, None)
    return net</div>
</pre>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">NeuroLab 0.2.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, eje.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>